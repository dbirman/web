<!DOCTYPE HTML>
<!--
	Landed by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Dan's World</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="../assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body>
		<div id="page-wrapper">


			<!-- Header -->
				<header id="header">
					<h1 id="logo"><a href="index.html">Dan Birman</a></h1>
					<nav id="nav">
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="research.html">Research</a></li>
							<li><a href="teaching.html">Teaching</a></li>
							<li><a href="tools.html">Tools</a></li>
						</ul>
					</nav>
				</header>

			<!-- Main -->
				<div id="main" class="wrapper style1">
					<div class="container">
						<header class="major">
							<h2>Morality</h2>
						</header>

						<!-- Content -->
							<section id="content">

<p>
&ensp;An interesting problem that I often think about is how should we act if we want to minimize suffering in the world. I suppose this is a Buddhist philosophy originally, but I believe you can build it up from simple ideas about how consciousness functions in organisms. Without going into the details (coming later) I think the simple story is that our actions and our experiences are intertwined between organisms, and so when we make actions we should take into account the experiences of others as part of our own decisions. But this is a high-level, abstract kind of decision making. I think that most organisms are at a lower level, where their decisions are driven by stimulus-response mappings. Some organisms are at an intermediate level where decision making includes mental models of other organisms (most humans). Finally, this high-level abstract thinking involves judgments of experience that span larger numbers of organisms and are not exclusively in the interest of oneself. This is the rough groundwork, below I will expand in more detail on each of these ideas.<br>
&ensp;In regards to consciousness I won't go into much detail (see my consciousness essay) other than to say that organisms have been honed by evolution for survival. To this end organisms have a sense of the value of actions, and to some extent they choose actions based on maximizing value. Experiencing organisms feel value as happiness, sadness, pain, etc. This is true to some extent of all organisms that are conscious, obviously to a lesser or greater extent across species. Humans, for example, seem to have a particularly acute and developed sense of value. In contrast, most animals seem to have much simpler sensations of value closer to a simple scale from comfort<->pain and happiness<->sadness. The fact that all conscious organisms experience value to some extent is the baseline assumption that underlies a morality of consciousness, everything else is built upon this idea. In short: suffering, by definition the experience of negative value, should be minimized for selfish reasons, and therefore should be minimized across all organisms.<br>
&ensp;Before expanding on these ideas in the context of morality I want to take a moment to expand on the ideas of levels of decision making. These ideas have come to me over time from working with rodents and humans, and reading the experiences of other scientists with monkeys and large mammals. My understanding is that most conscious organisms likely experience the world as part of a sensorium that is much closer to being modality specific, e.g. more purely visual, auditory, or smell. For these organisms consciousness is a way of integrating multiple sensory experiences in a common workspace. In comparison humans have an additional representational capacity for abstract though and concepts, that are perhaps developed relative to sensory experiences but eventually become unlinked. In addition, only a subset of all conscious organisms have the capacity for theory of mind. These three attributes: modality specific thought, theory of mind, and abstract thoughts, split the continuum of conscious organisms into three rough groups. For simplicity I will refer to modal organisms as level 1, organisms with theory of mind as level 2, and organisms with abstract though as level 3. My bias toward putting these elements in a hierarchy is probably obvious.<br>
&ensp;<b>Level 1</b>What is it like to be a level 1 organism experiencing the world and acting upon it? I would remind the reader of the fish in the consciousness essay: this organisms has sensations and perceptions, but without reflecting upon them and with no impression of choice simply makes actions corresponding to the combination of inputs. This is sensory->response mapping, but in the much more complex space of the conscious global workspace--which is a common "field", relative to the organism, where sensations are represented so as to allow the brain to compute actions based on these inputs. This is in part a question of efficiency, many combinations of stimuli may lead to common actions, but learning all of these in single mappings would be a combinatorial problem. Mapping inputs into a common space out of which actions are mapped is just a computational simplification. The fact that this space is itself a simulation of the organism in the world is what leads it to be an experienced field rather than an unconscious one. So our fish has experiences but they are limited and lack any abstraction. It is impossible for our fish to create models of things like "colors", despite experiencing these, and sensations would not be differentiated into abstract categories like vision and audition. Finally, organisms at higher levels may act according to level 1 rules when their higher level capacities are limited, due for example to hunger, thirst, or overwhelming emotions. Instead of using their capacities for theory of mind and abstract though they may revert to impulsive decisions that are simply the highest value action for a particular situation.<br>
&ensp;<b>Level 2</b>The easiest way to imagine a level 2 organism is to think of the average human. Most humans have excellent theory of mind, able to empathize and sympathize with other humans and conscious organisms in general, but perhaps limited in their ability to employ abstract though. It is important to distinguish here between abstract thought in general, such as knowledge of colors as mentioned above, and the ability to manipulate abstract thoughts in the context of decision making. 




&ensp;Right now I think I have a major interest in taking apart a single question at multiple levels, ideally leveraged against the idea of how that leads to moral decisions. I believe that morality has three degrees:
(1)	Decisions made by an agent operating under the stress of a sensation
a.	Agents in the 1st degree think about themselves.
b.	Because of their pressing needs they cannot formulate mental models of other agents.
(2)	Decisions made by an agent operating under the stress of an emotion
a.	Agents in the 2nd degree can generate mental models of others, but they may consider some of those models to be more abstract (for example, animals) than those that have an emotional connection to them.
(3)	Decisions that are free of sensation and emotion.
a.	In the 3rd degree agents can form mental models about anybody, or anything, which allows them to ask questions such as: what would cause the least suffering for all of these things?
b.	Their answers will be minimally influenced by their state of being and the states of others.
&ensp;I think that morality has to appeal to people who are in the 3rd degree of freedom in this sense and that you cannot have a “rational” agent who is hungry, or sad, etc. What I would ideally like to study is whether these degrees can be identified in humans and second, how degrees 1 and 2 override our decision making ability.
&ensp;After talking to Tor and Randy I think that one way to work with them would be to look at how motivation and goal directed behavior is influenced by internal and external pressures/stresses, and how motivation/goal directed behavior influences the perception of those pressures.
The key here is that there are multiple things going on:
1.	The effect of INTERNAL pressures, especially affect and emotion, on motivation to pursue a goal.
2.	The effect of EXTERNAL pressures, suffering/feedback, on INTERNAL pressures.
3.	The effect of motivation on the PERCEPTION of an external pressure
4.	Whether perception or sensation better predict the influence of an external pressure.
&ensp;So let’s think a bit about what this means for neuroimaging. How do we actually study the influence of sensation and emotion on moral decision making? I think that this is a crucial question as we go into the 21st century: we are at a point where we understand that people are responsible for their decisions but ultimately they depend on many influences. We need to put people in court, in admission committees, and so on that are unbiased in as many ways as possible—they need to be acting at level three. So let’s consider brain activity, if we understand how people represent (via generative models) some kind of perception, then we can look at how they make decisions from this information. Finally, we can push them according to sensation or emotion and look at what happens.

The key here is the link between HUMAN BEHAVIOR and NEURAL ACTIVITY. The second link is between HUMAN BEHAVIOR and SUFFERING (a sensation). Finally, the third link is between SUFFERING and NEURAL ACTIVITY.
Take for example the way that diffusion to boundary (leaky accumulators?) work. If two populations of neurons are accumulating evidence for a house vs. face decision, where does the input from higher areas that influences the response come from. Also, how does the motivatiuon to produce one answer over the other factor into the variables? Does it bias things at the lowest possible level.

From (Heekeren, Marrett, && Ungerleider, 2008)
In general: sensory evidence “accumulates” for different alternatives simply based on the activation (linear) of some neural population. Downstream regions process these inputs (for binary choices via subtraction) until a threshold is reached, causing motor outcome to occur.
How performance- related and error-related signals generated in the monkey posterior medial frontal cortex influence sensory representations during perceptual decision making is not yet clear (Heekeren et al., 2008).
QUESTION: How is motivation, bias, etc introduced to these low-level brain regions. Is it represented in the higher regions or as a part of the sensory representation itself (i.e. via top-down influence).
dlPFC correlates with the difference of sensory regions and is maximum for clear stimuli 

(1)	The organization of a mind implies the presence of certain computational shortcuts, such as “pleasure, pain, suffering, etc”
(2)	These shortcuts allow us to make decisions more efficiently, the hierarchy of complexity being decisions based on sensation, perception, and reason.
a.	Efficient decisions often depend on variables that we do not access consciously, hence they can be influenced by the environment.
(3)	Because these computational shortcuts must be preserved across organisms, the group of dimensions that they encompass can be considered a “moral landscape” (Harris, 2011)
(4)	Given the existence of a generalized moral landscape, we can discuss the peaks and valleys of the landscape
(5)	Given our current position and idealized peaks, we can, SHOULD, and MUST motivate people to act in ways that move us towards those peaks.
Red is red (or whatever, house), for the same reason that happiness is happiness and suffering is suffering… solve that mystery and you’re onto something! My guess is this somehow has to do with the relationship within the mind space, so to speak? 

Start with very simple “organisms” and show what a morality would be like for them (or just what well-being is like), then extend that model upwards to more complex organisms.

(1)	What do people do in the name of morality (i.e. what are levels 1 + 2)
(2)	What is actual moral behavior (level 3) and how does it relate to being a conscious being
(3)	How do we convince everybody to do the right thing, even when acting at levels 1/2
(Sam Harris’ ideas, not mine)

How do you define well-being based on value

Other level concepts:
•	Organisms doing things for themselves and hurting others (selfish)
•	Organisms doing things for themselves, neutral to others
•	Organisms doing things for others, positive for them
•	Organisms doing things for others, negative for them (altruistic)
What is well-being? A way of tracking REWARD over TIME. Something is rewarding when it has value (intrinsic or learned), and you have a memory of that value.
</p>
							</section>


					</div>
				</div>

			<!-- Footer -->
				<footer id="footer">
					<ul class="copyright">
						<li>&copy; Dan Birman 2015</li><li><a href="https://github.com/dbirman/web/" target="_blank">Code<a/></li>
					</ul>
				</footer>


		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-34324563-2', 'auto');
  ga('send', 'pageview');

</script>