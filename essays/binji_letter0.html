<!DOCTYPE HTML>
<!--
	Landed by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Binji1</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="../assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body>
		<div id="page-wrapper">


			<!-- Header -->
				<header id="header">
					<h1 id="logo"><a href="index.html">Dan Birman</a></h1>
					<nav id="nav">
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="research.html">Research</a></li>
							<li><a href="teaching.html">Teaching</a></li>
							<li><a href="tools.html">Tools</a></li>
						</ul>
					</nav>
				</header>

			<!-- Main -->
				<div id="main" class="wrapper style1">
					<div class="container">
						<header class="major">
							<h2>Being Social and Conscious, a letter to Binji</h2>
						</header>

						<!-- Content -->
							<section id="content">

<p>
Dear Binji, thanks for the excellent letter and intriguing thoughts. There's a lot of great ideas in here and I should devote plenty of time to them, but you've already stated them nicely! So instead I'll just go on the attack and see how much damage I can do :). I see a short list of things that I want to address, which I'll outline here and then go into detail about.
<ul>
	<li>
		First, I take issue with the idea that a computational model of conscious experience is "as simple as" W->P->X->D->G->A. In particular, I think this is a classic example of a model that attempts to sidestep the hard problem.
	</li>
	<li>
		Second, I agree that the fundamental counter-argument to your approach is to argue that the first person perspective takes precedence. I disagree with your conclusion that percepts are inherently social--I think that categorical labels are social, but percepts are individual experiences.
	</li>
	<li>
		Third, you make an argument that the human evolutionary niche is inherently social. I agree, but I think there are some nuances to go into. For example you say "When we consider our own experience and the most important drivers of what we feel, neuron level impacts of psychoactive chemicals and food are much less impactful than our experience of social systems, and the environment" whereas I think these are one and the same.
	</li>
	<li>
		Finally, I think that when we think about suffering we have to use the atomic unit of the first person perspective. Although we are inherently social beings I believe we <i>do not</i> have conscious experiences independent of individual organisms. This means that all decisions with regards to suffering should only take into account the firts person perspective.
	</li>
</ul>
<h3>Hard Problem</h3>
Before diving in I want to start by taking a cautious step and defining the terms that I plan to use. Not because I think that we necessarily have distinct definitions but rather as an exercise for myself in carefully isolating different concepts. I believe <i>consciousness</i> is a simulation created with the purpose of solving the problem organisms continually face of choosing actions, when multiple possible action choices exist. The <i>conscious field</i> is a frame, defined by its contents, which are structured in relative positions to each other: it has dimensions of space, dimensions of color, dimensions of taste and smell, and so on. A given state of the conscious field will always lead to the same output action, whether that is an internal thought or external motor output. To <i>be conscious</i> of something is to have a percept active in the conscious field, and thus influencing the potential next actions of the organism. Importantly, percepts can be in conflict with each other, for example when are hungry and yet choose to not start eating out of politeness, or under water needing to breath but you choose not to. Why use a conscious field at all? Consciousness, which is the dynamic continuity of the field, is our organism's functional solution to allowing different stimuli that are perceived to exert equal influence on our actions. When we are unconscious, or unconscious of a stimulus, we can only map events on to particular responses. Consciousness allows vastly more complex actions by, for example, combining the stimulus of a face with the knowledge of who that face belongs to, leading to a far larger repertoire of possible action outcomes. As I see it this is a definition, but it lacks of course a solution to the hard problem, and is thus similar in computational usefulness as the mathematical definition that you quoted.
<br><br>
The hard problem will, I imagine, eventually be solved by the discovery that there is a way of simulating things, via computation--whether it be in humans or computers, such that the simulation thus computed experiences qualia. It may turn out that architecture matters but I doubt that <i>atomic structure</i> matters, so silica should be capable of this given the correct architecture. Why does answering the hard problem matter? Without it I think that all definitions of conscious, including the mathematical one quoted, are simply a complex set of input->output mappings. I believe that the hard problem, why qualia are actually experienced, is the core functional importance of consciousness. In my own view putting qualia into a common space gives them an emergent property: they are now in a relative space, which can be computed over. In other words, the percept of a tiger has a certain equivalence to the smell of smoke, in the sense that they are both qualia and are both in the conscious field, and they both exert an equal influence on the set of actions we might take next.  Any approach that hopes to make light of consciousness needs to explain the hard problem, and I don't think that it can be waved away either in mathematical terms (e.g. an arbitrary mapping) or philosphical ones (e.g. chalmers etc). Crucial to the response to your letter is that I don't see the hard problem as a social one. Although humans (and most mammals and many vertebrates) evolved in an environment where sociability confers a fitness advantage, I don't think this necessarily means that the hard problem solves a social problem. I think that social qualia, such as empathy, love, etc, confer social fitness. But I think that when these evolved originally they were taking advantage of an existing conscious field structure, which they added on to.
<br><br>
To finish out this section I want to quickly mention that I think any mathematical model of consciousness has an additional problem to contend with: the complexity of biology. Biological systems are <i>vastly</i> more complex than we often pretend they are, even human metabolism, which is simple compared to the brain and relatively well understood, involves thousands of chemicals and tens of thousands of chemical reactions, enzymes, catalysts, and proteins. Recent attempts to categorize neural structure have all run into the unbelievable diversity of computational units in the brain--in fact some people believe that the reason the brain is so adaptable and dynamic is precisely that each neural unit is attempting to survive on its own. In other words, every neuron might be thought of as "selfish", and in their joint selfishness at acquiring energy and reproducing they have the emergent property that the entire biological organism survives longer and trends towards reproduction and energy obtaining behaviors.


<br><br>
<h3>First Person Perspective</h3>
I alluded briefly above to the issue of what perspective is the correct one, a social perspective vs. a first person perspective. Here I will expand on why I think that the human niche is in fact perceptually first person, but socially third person. Previously I explained in my idea why I think there is a hard problem and that it isn't solved yet and now I want to add some nuance to this by suggesting, like you did in your letter, that it's possible to carve up perception into explicit and implicit representations. But contrary to the argument you present I think that the implicit forms are different.
<br><br>
The fact that we have spatial perceptions (e.g. proprioception/vision), non-spatial perceptions (smell), and formless perceptions (thoughts), seems to suggest that consciousness is not limited to simply the incoming sensory systems. My guess at this point, and without much evidence to back this up, is that it is possible to create a conscious percept of <i>anything</i>, so long as it has some relation to the conscious observer such that it can be represented in a "relative" format. By relative I mean that all percepts live along some continuum or high-dimensional manifold. An important point here: I want to distinguish percepts (points or trajectories in percept-space) from categories. Categories are a carving up of perceptual space into functional units and interestingly categories <i>themselves</i> can also be made into conscious percepts (whether they are represented as new points in space, or simply an emergent property of other percepts is unclear, although I imagine it is the former). So when you write that colors, emotions, etc are a social phenomenon my take on this is that these are in fact labels that are being placed upon categories. Because we are socially evolved creatures we also evolved towards coherent communication, and so we tend to converge on equivalent labels for things and, in a circular manner, we converge towards similar carvings of perceptual space. When these two equivalences are not maintained a social system consisting of multiple brains would likely have evolved to minimize conflict. The basic unit of perception in this view is something that is experienced by a single organism but interpreted amongst multiple organisms, according to the importance, in that organisms social niche, of coherent communication with regards to perception.
<br><br>
Let's dive into an example of this in the context of a non-linguistic organism since that, I hope, will make it more clear what I'm getting at. I prefer to use fish as my lowest-level conscious organism and so I'll do that here, although I'm not actually certain that fish are conscious. That issue aside, imagine for a moment a school of fish who experience only a single qualia: they experience a sphere of either <i>present</i> or <i>absent</i> signals, which represent other fish. In a fish mind if there are many small present signals they are safe within their own school, while if there is only a single large signal they are in danger. Immediately we have defined a dimension, valence, which has two endpoints: positive and negative, or safety and danger. Our hypothetical fish has two possible actions: to act according to its neighbors, or to swim as quiclky as possible away from the present signal. Now the issue: these actions are mutually exclusive, but the signals that the fish receives are continuous. How should the fish solve the problem of deciding, based on more or less ambiguous inputs, which action to take? I would argue here (as many others have) that the key solution is to categorize: set a threshold, or multiple thresholds, at which perception abruptly jumps between different categories. Each category is directly linked to a particular set of actions that the organism should take. Somewhere in the gray area between categories the fish most likely deploys additional attention to the target, e.g. by freezing and rotating to maximize perceptual inputs, and then subsequently takes an action when sufficient information is available. This model is entirely first person and this, for me, is the crux issue of social consciousness: this fish doesn't can learn in isolation how to survive, but to <i>efficiently</i> survive along with other fish it would be ideal to match up its categories with those of its kin. This is where social categories come from--the fitness benefit they confer goes beyond isolated first person categories, but they are always a form of super-category that goes beyond what is necessary for survival.
<br><br>
<h3>Neural Modulation vs. the Action Potential</h3>
This section is a bit of a tangent to the main point, but you mentioned something which I think bears digging into a bit deeper. I quoted above but will paraphrase here: social influences are "direct", whereas psychoactive chemicals/etc are "indirect" influences on the mind. I as I understand you this is part of a larger argument to say that humans are part of a much larger social structure--and that it's an incorrect leap to isolate humans from those social influences. I have two responses to this: first, I think this argument would benefit from some precision about how neural function can be altered which I think has some bearing on this, and second I want to add that while it's true that we can never be truly isolated from social influences there is nevertheless always the first person perspective issue (which I went into more detail about above).
<br>
To continue thinking about neural function I want to weigh in a bit about the biology of neurons. The reason that biologists believe neurons are the fundamental unit of computation in the brain is that they perform all of the necessary functions of a "logical" gate: they can take multiple inputs in space and time, depending on the strengths and relative weightings of those inputs they may or may not "fire" an output, and finally they can communicate that information to many other neurons (potentially thousands to tens of thousands, depending on neuron type). Neurons can only output signals through the "action potential" an all-or-none signaling mechanism that has a relatively constant output strength. In other words, neuron output signals are binary, but they compute non-linear functions of their input units. This is important because it means that even a short chain of randomly interconnected neurons (say 10,000) becomes a turing complete computer, or in other words this system can compute all computable mathematical functions. If you further break things down below the level of neurons this turing completeness begins to break down in various ways, so biologists are pretty certain that brain-level computations occur between neurons. In humans we know that only large groups of neurons correlate well with behavior, suggesting that in fact large systems of neurons work together in a <i>distributed code</i>. So back to the original point here: there are two ways to modify the action potential output of a neuron. You can either put in a sufficient number of action potentials (as inputs) such that your neuron fires an output or you can potentiate the neuron. By potentiation I mean altering the neuron's initial voltage to make it either easier or harder for this neuron to fire.
<br>
Mapping action potentials and potentiation back onto high-level influences isn't too difficult. Basically, psychoactive chemicals are a form of potentiation that occurs across enormous numbers (hundreds of millions) of neurons. In contrast, sensory perceptions occur primarily as direction action potential inputs into the system. Social influences are a mixed bag, as a first-pass they induce action potential inputs, but these can eventually cause the release of "bathing" chemicals in the brain, which cause large scale changes (e.g. you may have heard about dopamine, which when released represents reward and helps learning, or serotonin which is important for mood control). So to sum up this section I want to say that even in isolation a human brain may be experiencing all kinds of inputs and modulations due to chemicals, but the form of these inputs is important. In all cases these inputs exert influence through specific filtered sensory channels, or through non-specific "bathing" of the entire brain. I would hesitate to say that one form of input is more impactful than the other. Chemicals that modulate the entire brain cannot, by definition, directly alter thoughts/perceptions/feelings etc, they can only modulate them as they occur from other sources. 
<br><br>
<h3>Suffering</h3>
So this leads us back to the original thought: is suffering a social phenomenon? A more precise phrasing for me would be: in the absence of other organisms, e.g. in isolation on mars as you suggested, would a human grow to experience suffering? There are a few caveats here to consider: one is that they wouldn't be able to communicate their suffering to us, which would make it hard to tell that they were suffering--but I will come back and explain why I don't think this is a problem, but also important is that in the absence of other humans it isn't totally clear what they would experience, if anything, as you pointed out. So to make progress with this exposition I need to take a detour, relying on the points outlined above, to explain why I think suffering is <i>experienced consciously</i>, why it is experienced <i>from a first person perspective</i>, and why it is <i>not a form of neural modulation</i>. To the first point I think this can be resolved by asking whether suffering, as an experience, has a function which would require conscious perception rather than unconscious processing. I think the argument for perception goes as follows: unconscious processing can only enable precise stimulus -> response mappings, in the absence of conflict. But suffering, or the experience of negative valence in general, covers both situtations that may require conflicting motor outputs and those that do not. Escaping from a predator may simply require moving away from it, but navigating PTSD might require much more complex actions. So there are negative valence stimuli that could be unconscious by this rule and there are other negative valence stimuli that are unlikely to be unconscious. But what does suffering provide for an organism? I think the answer to this question explains the second point, why it would be first person. I believe that valence is a fast judgment that organisms make of all stimuli, an attempt to place them on the evolutionary continuum of fitness: either they reduce fitness, or they increase it. Suffering is a category (note that it is a category, not a base percept) which encompasses some of the negative valence percepts. Crucially, these base percepts are first person perspectives--but the concept of suffering, insofar as it is more than just the perceptions of pain/fear/etc, is a social phenomenon. Finally, very briefly, suffering comes from stimuli, it is not a state of being, but an interpretation of incoming stimuli, possibly within a negative context, so it is unlikely to be simply a neural modulation (as an example consider depression, a careful read of depression symptoms shows that they are in fact a <i>change in interpretation</i> of stimuli that would normally evoke a different response under other circumstances).
<br><br>
We've now established that there are base percepts that are experienced which provoke an organism towards actions that reduce those experiences. These experiences are inherently bad: they are the only signal an organism has at its disposal to know that its evolutionary fitness is at risk. But, above and beyond these base percepts our social evolution has pushed us to create a shared category of experiences. This coherent structure of bad experiences is suffering itself, a concept that is more than just bad perceptions, but bad perceptions <i>in general</i>. So this is for me the end of this essay and the establishment, in my mind, that suffering is a social phenomenon, to the extent that social pressures define what we call "suffering" and our interpretation of it. But the perceptual experiences that are a part of the category of suffering are not social, in fact they <i>must</i> not be social, or they would fail to exert evolutionary pressure on individual organisms. As a final point I would add that its possible that individual experiences of suffering can be over-ruled by the social concept of suffering, such that one person pain is tolerated for the sake of increased social fitness, see e.g. "the ones who walk away from omelas" for a prime example. Note that this is also a prime example of the distinction between first person pain and social suffering: when one person suffers to increase the group's fitness this is no way diminishes their individual first person experiences of pain, except that they may be able to mask it at a higher "mental" level. 
<br><br>
To end this essay I want to look forward though, and propose that suffering thus defined is in fact a very powerful concept and part of the cognitive toolkit. I think that a philosophy of living, or a guide for how to live, for humans needs to take into account that suffering is such a basic concept for us. We evolved to be sensitive to certain negative stimuli because they alter out evolutionary fitness, and these same stimuli cause bad perceptions, which we in turn categorize as suffering (when these are not in conflict with evolutionary fitness at the social level). A moral society in my mind is one that takes into account suffering as defined here and notices that the needs of social fitness should never outweigh the needs of individual fitness. It is the individual who experiences--never the group, and so group fitness is always secondary to individual fitness. Whether or not evolutionary fitness is a value to strive for would be a topic for another essay, but briefly here I'll say that I think evolutionary fitness is a poor place to search for moral values. But I also believe it is the only place that modern man has ever searched for moral values in the past, and even religion and philosophy derive all their values for evolutionary fitness, even if they fail to see it.
<br><br>
When I look at the future I often try to imagine: what will people think is moral in 100, 1000, 10000 years? I think that one answer might be the following: to act morally towards an organism is to take into account its internal valuation function. For humans and all organisms on earth this comes directly from evolutionary fitness. With this value function known, we must minimize the experience of negative values, except when negative values are the only way to learn or survive a situation.
</p>
							</section>


					</div>
				</div>

			<!-- Footer -->
				<footer id="footer">
					<ul class="copyright">
						<li>&copy; Dan Birman 2016</li><li><a href="https://github.com/dbirman/web/" target="_blank">Code<a/></li>
					</ul>
				</footer>


		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-34324563-2', 'auto');
  ga('send', 'pageview');

</script>