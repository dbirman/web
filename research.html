<!DOCTYPE HTML>
<!--
	Landed by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Research</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<!--[if lte IE 8]><script src="assets/js/ie/html5shiv.js"></script><![endif]-->
		<link rel="stylesheet" href="assets/css/main.css" />
		<!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
		<!--[if lte IE 8]><link rel="stylesheet" href="assets/css/ie8.css" /><![endif]-->
	</head>
	<body>
		<div id="page-wrapper">

			<!-- Header -->
				<header id="header">
					<h1 id="logo"><a href="index.html">Dan Birman</a></h1>
					<nav id="nav">
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="research.html">Research</a></li>
							<li><a href="teaching.html">Teaching</a></li>
						</ul>
					</nav>
				</header>

			<!-- Main -->
				<div id="main" class="wrapper style1">
					<div class="container">
						<header class="major">
							<h3>
								I am interested in understanding consciousness: how do neurons evoke consciousness and what is the functional importance of conscious perception?
							</h3>
						</header>

						<!-- Content -->
							<section id="content">
								<!-- <img class="image fit" src="images/climb/linville.JPG" alt="" /> -->
								<!-- <img src="images/stanford.png"></img> -->
								<h2>Stanford University</h2>

								<h3 style="color:#ff5050">Limits of perception</h3>
								<p>Consciousness brings information into a "conscious field" from which it can be verbally reported, used for learning, stored in memory, etc. But we can also learn stereotyped behaviors without any conscious access. If you've ever driven home without realizing where you went you know this. But you probably learned to drive while paying attention and fully conscious. This project is focused on figuring out whether it is possible to learn complex abstract behaviors, like driving, even when you are completely unconscious of the relevant perceptions.</p>
								<p>with Justin Gardner at <a href="http://gru.stanford.edu/doku.php" target="_blank">Gardner Lab</a></p>

								<h3 style="color:#ff5050">Mechanisms of visual attention</h3>
								<p>Attending to a location or feature in a scene increases the chances that a stimulus will reach conscious perception. But this comes at cost. Other visual features that would normally be processed are often rendered unconscious, an effect known as inattentional blindness. What neural mechanism is responsible for this? In this experiment we investigate attention to contrast and motion and show that a simple model of brain responses is sufficient to capture this effect.</p>
								<p>with Justin Gardner at <a href="http://gru.stanford.edu/doku.php" target="_blank">Gardner Lab</a>; <a href="https://github.com/dbirman/att_awe/" target="_blank">Code</a>; <a href="https://github.com/justingardner/grustim/blob/master/cohcon.m" target="_blank">Stim</a>; Data (available after publication)</p>

								<h3 style="color:#ff5050">What is it like to be a monkey?</h3>
								<p>We have an intuition that other animals perceive the world much the way that we do. Curiosly, when you try to teach animals simple tasks, such as pressing a button when two events are identical, they have a terribly hard time learning this. Is this because the animals actually see the world differently? Check out our news and views to learn more.<br><br>	
								PDF available: <a href="./assets/pdfs/birman_nn_2016.pdf"><img src="./images/ico/pdf-icon.png" style="width:4%"/></a>
								</p>
								<p>
									Birman, D., & Gardner, J. L. (2016). Parietal and prefrontal: categorical differences?. Nature neuroscience, 19(1), 5-7. at <a href="http://gru.stanford.edu/doku.php/categorization/" target="_blank">Gardner Lab</a>; <a href="https://github.com/dbirman/freedman_rep/" target="_blank">Code, Stim, + Data</a>
								</p>

								<h3 style="color:#ff5050">Applying 3D deep neural networks to human psychophysics</h3>
								<p>A CS231n class project. Our goal was to see whether convolutional neural networks could replicate the performance of humans on simple stimulus strength discrimination tasks. If you're interested in this idea get in touch, extending this project would make an interesting undergraduate project.</p>
								<a href="./assets/pdfs/poster_cs231n_2016.pdf"><img src="./images/ico/poster_cs231n_2016.png" style="width:20%"/></a>
								<p>
									with Dylan Cable and Steeve Laquitaine at <a href="http://gru.stanford.edu/doku.php" target="_blank">Gardner Lab</a>; <a href="https://github.com/dbirman/motnet/" target="_blank">Code</a>; <a href="http://gru.stanford.edu/doku.php/deepmotion" target="_blank">Visuals</a>
								</p>
								
								<hr>
								<h2>BCCN Berlin</h2>
								<h3 style="color:#ff5050">Testing the global workspace theory</h3>
								<p>This is a pilot project in Fall 2016 looking at how visual information is spread through the brain when consciously accessible.</p>
								<p>with John-Dylan Haynes at <a href="https://sites.google.com/site/hayneslab/" target="_blank">hayneslab</a></p>
								<h3 style="color:#ff5050">The point of no return in vetoing self-initiated movements</h3>
								<p>
								We have an intuition that we "commit" to a decision at a specific moment, but much evidence has suggested that we actually construct our intentions after they happen. This is in stark contrast to brain activity which becomes predictive of actions far in advance, up to 10 seconds. In this experiment we showed that in reality the point of no return, after which an action (a foot movement) is guaranteed to happen, occurs 200 ms before motor activity in the leg. Before then the brain has not committed to beginning the action with no possibility of a cancellation.
								<br><br>
								PDF available: <a href="./assets/pdfs/birman_pnas_2015.pdf" style="text-decoration:none;"><img src="./images/ico/pdf-icon.png" style="width:4%"/></a>
								</p>
								<p>
									Birman, D.*, Schultze-Kraft, M.*, Rusconi, M., Allefeld, C., Görgen, K., Dähne, S., ... & Haynes, J. D. (2015). The point of no return in vetoing self-initiated movements. Proceedings of the National Academy of Sciences, 201513569. *Equal author contribution. at <a href="https://sites.google.com/site/hayneslab/" target="_blank">hayneslab</a> 
								</p>
							</section>

					</div>
				</div>

			<!-- Footer -->
				<footer id="footer">
					<ul class="copyright">
						<li>&copy; Dan Birman 2015</li><li><a href="https://github.com/dbirman/web/" target="_blank">Code<a/></li>
					</ul>
				</footer>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','http://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-34324563-2', 'auto');
  ga('send', 'pageview');

</script>